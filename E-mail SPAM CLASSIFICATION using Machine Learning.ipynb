{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# ****-------Notebook Summary----***\n\n#Data Science, Machine Learning\n\n#Data Visualization,EDA Analysis, Data Pre-processing,Data Cleaning,Data Split\n#-------------------------------------------------------------------------------------------------\n#Machine Learning Algorithm:\n#Natural Languaes Processing(NLP)\n#Best Model accuracy:model_3: 99.31%\n#Visualize output at graph\n\n#Original Source:https://www.kaggle.com/sohelranaccselab/e-mail-spam-classification-using-machine-learning","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Enivornment Setup","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import libraries\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize, sent_tokenize\n\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\n\nfrom collections import Counter\nimport string\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data Read, Data Visualization,EDA Analysis,Data Pre-Processing,Data Splitting","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data Read\nfile_path = '/kaggle/input/lingspam-classification'\ndf = pd.read_csv(f'{file_path}/messages.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn; seaborn.set()\ndf.plot();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the target variable countplot\nsns.countplot(data=df,x = 'label',palette='plasma')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting all messages to lower case\n\ndf['message'] = df['message'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check data once \ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.apply(lambda x: sum(x.isnull()),axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.fillna(df['subject'].mode().values[0],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.apply(lambda x: sum(x.isnull()),axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Engineering:\nTo get clarity about mail i'm going to merge both subject and message"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sub_mssg']=df['subject']+df['message']\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sub_mssg'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['length']=df['sub_mssg'].apply(len)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now i'm going to drop un-necessary features \ndf.drop('subject',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check it once \ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"lb=df['label'].value_counts().index.tolist()\nval=df['label'].value_counts().values.tolist()\nexp=(0.025,0)\nclr=('orange','blue')\nplt.figure(figsize=(10,8),dpi=140)\nplt.pie(x=val,explode=exp,labels=lb,colors=clr,autopct='%2.0f%%',pctdistance=0.5, shadow=True,radius=0.9)\nplt.legend([\"0 = NO SPAM\",'1 = SPAM'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preprocessing Email Messages :"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['message'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decontact(phrase):\n    # specific\n    phrase = re.sub(r\"won't\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n\n    # general\n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n    return phrase","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mssg=decontact(df['message'][70])\nmssg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#REPLACING NUMBERS\ndf['sub_mssg']=df['sub_mssg'].str.replace(r'\\d+(\\.\\d+)?', 'numbers')\ndf['sub_mssg'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CONVRTING EVERYTHING TO LOWERCASE\ndf['sub_mssg']=df['sub_mssg'].str.lower()\n#REPLACING NEXT LINES BY 'WHITE SPACE'\ndf['sub_mssg']=df['sub_mssg'].str.replace(r'\\n',\" \") \n# REPLACING EMAIL IDs BY 'MAILID'\ndf['sub_mssg']=df['sub_mssg'].str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$','MailID')\n# REPLACING URLs  BY 'Links'\ndf['sub_mssg']=df['sub_mssg'].str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$','Links')\n# REPLACING CURRENCY SIGNS BY 'MONEY'\ndf['sub_mssg']=df['sub_mssg'].str.replace(r'£|\\$', 'Money')\n# REPLACING LARGE WHITE SPACE BY SINGLE WHITE SPACE\ndf['sub_mssg']=df['sub_mssg'].str.replace(r'\\s+', ' ')\n\n# REPLACING LEADING AND TRAILING WHITE SPACE BY SINGLE WHITE SPACE\ndf['sub_mssg']=df['sub_mssg'].str.replace(r'^\\s+|\\s+?$', '')\n#REPLACING CONTACT NUMBERS\ndf['sub_mssg']=df['sub_mssg'].str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$','contact number')\n#REPLACING SPECIAL CHARACTERS  BY WHITE SPACE \ndf['sub_mssg']=df['sub_mssg'].str.replace(r\"[^a-zA-Z0-9]+\", \" \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CONVRTING EVERYTHING TO LOWERCASE\ndf['message']=df['message'].str.lower()\n#REPLACING NEXT LINES BY 'WHITE SPACE'\ndf['message']=df['message'].str.replace(r'\\n',\" \") \n# REPLACING EMAIL IDs BY 'MAILID'\ndf['message']=df['message'].str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$','MailID')\n# REPLACING URLs  BY 'Links'\ndf['message']=df['message'].str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$','Links')\n# REPLACING CURRENCY SIGNS BY 'MONEY'\ndf['message']=df['message'].str.replace(r'£|\\$', 'Money')\n# REPLACING LARGE WHITE SPACE BY SINGLE WHITE SPACE\ndf['message']=df['message'].str.replace(r'\\s+', ' ')\n\n# REPLACING LEADING AND TRAILING WHITE SPACE BY SINGLE WHITE SPACE\ndf['message']=df['message'].str.replace(r'^\\s+|\\s+?$', '')\n#REPLACING CONTACT NUMBERS\ndf['message']=df['message'].str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$','contact number')\n#REPLACING SPECIAL CHARACTERS  BY WHITE SPACE \ndf['message']=df['message'].str.replace(r\"[^a-zA-Z0-9]+\", \" \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sub_mssg'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize, sent_tokenize\n# removing stopwords \nstop = stopwords.words('english')\ndf['Cleaned_Text'] = df['sub_mssg'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('message',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('sub_mssg',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.apply(lambda x: sum(x.isnull()),axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['lgth_clean']=df['Cleaned_Text'].apply(len)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"original_length=sum(df['length'])\nafter_cleaning=sum(df['lgth_clean'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"original_length\",original_length)\nprint('after_cleaning',after_cleaning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1. Convert text into vectors using TF-IDF\n# 2. Instantiate MultinomialNB classifier\n# 3. Split feature and label\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nimport warnings\nfrom sklearn.pipeline import Pipeline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tvec = TfidfVectorizer()\nlr = LogisticRegression(solver = \"lbfgs\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.Cleaned_Text\nY = df.label\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, random_state = 42,stratify=Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Pipeline([('vectorizer',tvec),('classifier',lr)])\n\nmodel.fit(X_train,Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ny_pred = model.predict(X_test)\n\nconfusion_matrix(y_pred,Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy : \", accuracy_score(y_pred,Y_test))\nprint(\"Precision : \", precision_score(y_pred,Y_test, average = 'weighted'))\nprint(\"Recall : \", recall_score(y_pred,Y_test, average = 'weighted'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knc = KNeighborsClassifier()\nmodel_1 = Pipeline([('vectorizer',tvec),('classifier',knc)])\nmodel_1.fit(X_train,Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model_1.predict(X_test)\n\nprint(confusion_matrix(y_pred,Y_test))\nprint(\"Accuracy : \", accuracy_score(y_pred,Y_test))\nprint(\"Precision : \", precision_score(y_pred,Y_test, average = 'weighted'))\nprint(\"Recall : \", recall_score(y_pred,Y_test, average = 'weighted'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abc = AdaBoostClassifier()\nmodel_3 = Pipeline([('vectorizer',tvec),('classifier',abc)])\nmodel_3.fit(X_train,Y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model_3.predict(X_test)\n\nprint(confusion_matrix(y_pred,Y_test))\nprint(\"Accuracy : \", accuracy_score(y_pred,Y_test))\nprint(\"Precision : \", precision_score(y_pred,Y_test, average = 'weighted'))\nprint(\"Recall : \", recall_score(y_pred,Y_test, average = 'weighted'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mnb = MultinomialNB()\nmodel_5 = Pipeline([('vectorizer',tvec),('classifier',mnb)])\nmodel_5.fit(X_train,Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model_5.predict(X_test)\n\nprint(confusion_matrix(y_pred,Y_test))\nprint(\"Accuracy : \", accuracy_score(y_pred,Y_test))\nprint(\"Precision : \", precision_score(y_pred,Y_test, average = 'weighted'))\nprint(\"Recall : \", recall_score(y_pred,Y_test, average = 'weighted'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbc = GradientBoostingClassifier()\nmodel_6= Pipeline([('vectorizer',tvec),('classifier',gbc)])\nmodel_6.fit(X_train,Y_train)\n\n\ny_pred = model_6.predict(X_test)\nprint(confusion_matrix(y_pred,Y_test))\nprint(\"Accuracy : \", accuracy_score(y_pred,Y_test))\nprint(\"Precision : \", precision_score(y_pred,Y_test, average = 'weighted'))\nprint(\"Recall : \", recall_score(y_pred,Y_test, average = 'weighted'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier as RFC\nrfc = RFC(random_state=42)\nmodel_7 = Pipeline([('vectorizer',tvec),('classifier',rfc)])\n\nmodel_7.fit(X_train,Y_train)\n\ny_pred = model_7.predict(X_test)\nprint(confusion_matrix(y_pred,Y_test))\nprint(\"Accuracy : \", accuracy_score(y_pred,Y_test))\nprint(\"Precision : \", precision_score(y_pred,Y_test, average = 'weighted'))\nprint(\"Recall : \", recall_score(y_pred,Y_test, average = 'weighted'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using RandomForestRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators=1000,random_state=2520)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel_8 = Pipeline([('vectorizer',tvec),('classifier',rfc)])\n\nmodel_8.fit(X_train,Y_train)\n\ny_pred = model_8.predict(X_test)\nprint(confusion_matrix(y_pred,Y_test))\nprint(\"Accuracy : \", accuracy_score(y_pred,Y_test))\nprint(\"Precision : \", precision_score(y_pred,Y_test, average = 'weighted'))\nprint(\"Recall : \", recall_score(y_pred,Y_test, average = 'weighted'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=0.7795918367346939,\n              learning_rate=0.325, max_delta_step=0, max_depth=22,\n              min_child_weight=1, missing=None, n_estimators=833, n_jobs=1,\n              nthread=None, objective='binary:logistic', random_state=0,\n              reg_alpha=0.25, reg_lambda=2, scale_pos_weight=1, seed=None,\n              silent=None, subsample=1, verbosity=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel_9 = Pipeline([('vectorizer',tvec),('classifier',xgb)])\n\nmodel_9.fit(X_train,Y_train)\n\ny_pred = model_9.predict(X_test)\nprint(confusion_matrix(y_pred,Y_test))\nprint(\"Accuracy : \", accuracy_score(y_pred,Y_test))\nprint(\"Precision : \", precision_score(y_pred,Y_test, average = 'weighted'))\nprint(\"Recall : \", recall_score(y_pred,Y_test, average = 'weighted'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Testing Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"result=model_9.predict(['your microsoft account has been compromised ,you must update before or else your account going to close click to update'])\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result=model_9.predict(['Today we want to inform you that the application period for 15.000 free Udacity Scholarships in Data Science is now open! Please apply by November 16th, 2020 via https://www.udacity.com/bertelsmann-tech-scholarships.'])\nresult","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1 is normal message."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Here 0 is spam and 1 is normal message.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result=model_3.predict(['your microsoft account has been compromised ,you must update before or else your account going to close click to update'])\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result=model_3.predict(['Today we want to inform you that the application period for 15.000 free Udacity Scholarships in Data Science is now open! Please apply by November 16th, 2020 via https://www.udacity.com/bertelsmann-tech-scholarships.'])\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}